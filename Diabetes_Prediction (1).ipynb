{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"id": "a0c6ef68-91c7-4f39-a03f-9696315ef7b8", "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='rccqR6pMXx6bHjl0NHTz_z_qvDbfJh1M2w8sUJxroxnJ',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.direct.eu-gb.cloud-object-storage.appdomain.cloud')\n\nbucket = 'dataanalyticsproject-donotdelete-pr-gjuqfqeiunvnhj'\nobject_key = 'Diabetes Prediction Dataset.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_1 = pd.read_csv(body)\ndf_1.head(10)", "metadata": {"id": "a0c6ef68-91c7-4f39-a03f-9696315ef7b8"}, "outputs": [{"execution_count": 5, "output_type": "execute_result", "data": {"text/plain": "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n0  Female  80.0             0              1           never  25.19   \n1  Female  54.0             0              0         No Info  27.32   \n2    Male  28.0             0              0           never  27.32   \n3  Female  36.0             0              0         current  23.45   \n4    Male  76.0             1              1         current  20.14   \n5  Female  20.0             0              0           never  27.32   \n6  Female  44.0             0              0           never  19.31   \n7  Female  79.0             0              0         No Info  23.86   \n8    Male  42.0             0              0           never  33.64   \n9  Female  32.0             0              0           never  27.32   \n\n   HbA1c_level  blood_glucose_level  diabetes  \n0          6.6                  140         0  \n1          6.6                   80         0  \n2          5.7                  158         0  \n3          5.0                  155         0  \n4          4.8                  155         0  \n5          6.6                   85         0  \n6          6.5                  200         1  \n7          5.7                   85         0  \n8          4.8                  145         0  \n9          5.0                  100         0  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>smoking_history</th>\n      <th>bmi</th>\n      <th>HbA1c_level</th>\n      <th>blood_glucose_level</th>\n      <th>diabetes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>never</td>\n      <td>25.19</td>\n      <td>6.6</td>\n      <td>140</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Female</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>27.32</td>\n      <td>6.6</td>\n      <td>80</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>27.32</td>\n      <td>5.7</td>\n      <td>158</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Female</td>\n      <td>36.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>current</td>\n      <td>23.45</td>\n      <td>5.0</td>\n      <td>155</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>76.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>current</td>\n      <td>20.14</td>\n      <td>4.8</td>\n      <td>155</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>27.32</td>\n      <td>6.6</td>\n      <td>85</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Female</td>\n      <td>44.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>19.31</td>\n      <td>6.5</td>\n      <td>200</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Female</td>\n      <td>79.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>23.86</td>\n      <td>5.7</td>\n      <td>85</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Male</td>\n      <td>42.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>33.64</td>\n      <td>4.8</td>\n      <td>145</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Female</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>27.32</td>\n      <td>5.0</td>\n      <td>100</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}], "execution_count": 5}, {"id": "7a88c9b9", "cell_type": "code", "source": "\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Load dataset\ndf = pd.read_csv(\"Diabetes Prediction Dataset.csv\")\n\n# Display basic dataset information\ndf.info()\ndf.head()\n", "metadata": {"id": "158dee53-59b0-47d0-b913-df6a718ce60d"}, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, classification_report\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiabetes Prediction Dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Display basic dataset information\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Diabetes Prediction Dataset.csv'"], "ename": "FileNotFoundError", "evalue": "[Errno 2] No such file or directory: 'Diabetes Prediction Dataset.csv'", "output_type": "error"}], "execution_count": 6}, {"id": "ca124b05", "cell_type": "code", "source": "\n# Encode categorical variables\nle = LabelEncoder()\ndf['gender'] = le.fit_transform(df['gender'])\ndf['smoking_history'] = le.fit_transform(df['smoking_history'])\n\n# Define features and target\nX = df.drop(columns=['diabetes'])\ny = df['diabetes']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize numerical features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n", "metadata": {"id": "f5f0c3d9-fc30-4532-85f9-2b39a6a182a1"}, "outputs": [], "execution_count": null}, {"id": "f39b8f85", "cell_type": "code", "source": "\n# Visualizing data distribution\nplt.figure(figsize=(10,6))\nsns.histplot(df['age'], bins=30, kde=True)\nplt.title('Age Distribution')\nplt.show()\n\n# Correlation heatmap\nplt.figure(figsize=(10,6))\nsns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title('Feature Correlation Heatmap')\nplt.show()\n", "metadata": {"id": "7bce4a09-f4ee-4e27-b20f-147cc2eca49a"}, "outputs": [], "execution_count": null}, {"id": "b2f3c490", "cell_type": "code", "source": "\n# Train a Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred = model.predict(X_test)\n\n# Evaluate model performance\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\nprint('Classification Report:\\n', classification_report(y_test, y_pred))\n", "metadata": {"id": "342b236a-b979-4039-ac4f-ed76d4fd83ae"}, "outputs": [], "execution_count": null}]}